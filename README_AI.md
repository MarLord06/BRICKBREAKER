# ğŸ® Brick Breaker con IA - Sistema Completo

## ğŸ“‹ DescripciÃ³n

Sistema de Brick Breaker con **3 modos de control** y recolecciÃ³n automÃ¡tica de datos:

1. **ğŸ–ï¸ Manual** - Control con la mano usando MediaPipe (lento para datos)
2. **ğŸ¯ HeurÃ­stica** - IA perfecta que simula fÃ­sica (IDEAL para generar datos)
3. **ğŸ§  Neural** - Red neuronal GRU que aprende de la heurÃ­stica

## ğŸš€ Uso RÃ¡pido

### 1. Jugar con HeurÃ­stica (Recomendado para empezar)

```bash
python3 brick_breaker_tensorflow.py
```

**Controles en el juego:**
- `H` - Cambiar a modo HeurÃ­stica
- `M` - Cambiar a modo Manual
- `N` - Cambiar a modo Neural
- `ESC` - Salir

### 2. Entrenar la Red Neuronal

```bash
python3 train_neural_ai.py
```

Selecciona opciÃ³n **3** (30,000 ejemplos) - tarda ~8 minutos.

La red neuronal aprenderÃ¡ automÃ¡ticamente de la heurÃ­stica perfecta.

### 3. Usar la Red Neuronal

DespuÃ©s de entrenar, presiona `N` en el juego para cambiar a modo Neural.

## ğŸ“Š ComparaciÃ³n de Modos

| Modo | PrecisiÃ³n | Velocidad | Uso Principal |
|------|-----------|-----------|---------------|
| **HeurÃ­stica** | 100% perfecta | InstantÃ¡nea | GeneraciÃ³n de datos, benchmark |
| **Neural** | ~95% (con entrenamiento) | RÃ¡pida | ExperimentaciÃ³n con ML |
| **Manual** | Depende del jugador | Variable | DiversiÃ³n, validaciÃ³n |

## ğŸ¯ Flujo de Trabajo Recomendado

### Para RecolecciÃ³n de Datos (RÃPIDO):

La heurÃ­stica genera datos automÃ¡ticamente durante el entrenamiento. **No necesitas jugar manualmente**.

```bash
# Entrenar directamente (genera datos internamente)
python3 train_neural_ai.py
# Selecciona opciÃ³n 3 o 4
```

### Para Experimentar:

```bash
# 1. Ver la heurÃ­stica en acciÃ³n
python3 brick_breaker_tensorflow.py
# Presiona H

# 2. Entrenar la red neuronal
python3 train_neural_ai.py

# 3. Probar la red neuronal
python3 brick_breaker_tensorflow.py
# Presiona N
```

## ğŸ§  Arquitectura de la Red Neuronal

**Tipo:** Red Recurrente (GRU)

**Entrada:** Secuencia de 5 frames con 4 features cada uno
- ball_x (normalizado 0-1)
- ball_y (normalizado 0-1)  
- dx (velocidad X, normalizado -1 a 1)
- dy (velocidad Y, normalizado -1 a 1)

**Arquitectura:**
```
Input(5, 4) â†’ GRU(64) â†’ Dense(64,relu) â†’ Dropout(0.2) â†’ Dense(32,relu) â†’ Dense(1,sigmoid)
```

**Salida:** PosiciÃ³n X objetivo de la paleta (0-1, desnormalizado a pÃ­xeles)

## ğŸ“ˆ Ventajas de la HeurÃ­stica

âœ… **Perfecta:** Calcula exactamente dÃ³nde caerÃ¡ la pelota
âœ… **RÃ¡pida:** Genera miles de muestras en segundos
âœ… **Consistente:** No falla nunca
âœ… **Educativa:** Muestra la soluciÃ³n Ã³ptima
âœ… **Benchmark:** Para comparar el rendimiento de la red neuronal

## ğŸ”§ Archivos

- `ai_player.py` - Clases HeuristicAI y BrickBreakerAI (GRU)
- `train_neural_ai.py` - Script de entrenamiento
- `brick_breaker_tensorflow.py` - Juego principal con 3 modos
- `checkpoints/brickbreaker_model.keras` - Modelo entrenado (despuÃ©s de entrenar)

## ğŸ’¡ Tips

1. **Usa la heurÃ­stica primero** para entender cÃ³mo funciona el juego perfectamente
2. **La red neuronal es experimental** - puede fallar algunos golpes
3. **No necesitas jugar manualmente** para recolectar datos
4. **MÃ¡s datos = mejor red neuronal** (prueba con 50,000 ejemplos)

## âš™ï¸ Requisitos

```bash
pip install tensorflow opencv-python mediapipe numpy
```

## ğŸ“ Conceptos de IA

**HeurÃ­stica:** Algoritmo basado en reglas y fÃ­sica. Siempre perfecto pero no "aprende".

**Red Neuronal:** Aprende patrones de los datos. Puede generalizar pero tiene error de aproximaciÃ³n.

**Por quÃ© usar ambos:** La heurÃ­stica es el "profesor perfecto" que enseÃ±a a la red neuronal.

---

**Â¡Disfruta jugando y experimentando con IA!** ğŸš€
